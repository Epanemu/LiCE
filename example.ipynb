{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34d714c-9684-4601-96e1-f4c944bb1747",
   "metadata": {},
   "source": [
    "# LiCE minimal example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c97ede-1849-4b1c-bee5-bc081d2139e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from LiCE.data.DataHandler import DataHandler\n",
    "from LiCE.data.Features import Monotonicity\n",
    "from LiCE.spn.SPN import SPN\n",
    "from LiCE.lice.LiCE import LiCE\n",
    "\n",
    "from nn_model import NNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad528d04-8c59-4a4e-b7ed-1198a7c13555",
   "metadata": {},
   "source": [
    "## Prepare data and models\n",
    "### Setup data context (mutability, feature types...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea63b5d-3949-4ae3-a02e-3a0a18db1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/GMSC/cs-training.csv\", index_col=0).dropna()\n",
    "X = data[data.columns[1:]]\n",
    "y = data[[\"SeriousDlqin2yrs\"]]\n",
    "\n",
    "# set bounds on feature values\n",
    "# either fixed by domain knowledge\n",
    "bounds = {\"RevolvingUtilizationOfUnsecuredLines\": (0, 1), \"DebtRatio\": (0, 2)}\n",
    "# or take them from the data\n",
    "for col in X.columns:\n",
    "    if col not in bounds:\n",
    "        bounds[col] = (X[col].min(), X[col].max())\n",
    "\n",
    "config = {\n",
    "    \"categ_map\": {}, # categorical features, map from feature names to a list of categ values, e.g. {\"sex\": [\"male\", \"female\"] | if one provides an empty list with a feature name, then all unique values are taken as categories - note that training split does not have to include all values...\n",
    "    \"ordered\": [], # list of featurenames that contain ordered categorical values, e.g. education levels\n",
    "    \"discrete\": [\n",
    "        \"NumberOfTime30-59DaysPastDueNotWorse\",\n",
    "        \"age\",\n",
    "        \"NumberOfOpenCreditLinesAndLoans\",\n",
    "        \"NumberOfTimes90DaysLate\",\n",
    "        \"NumberRealEstateLoansOrLines\",\n",
    "        \"NumberOfTime60-89DaysPastDueNotWorse\",\n",
    "        \"NumberOfDependents\",\n",
    "    ], # contiguous discrete fearures\n",
    "    \"bounds_map\": bounds, # bounds on all contiguous values\n",
    "    \"immutable\": [\"NumberOfDependents\"], # features that cannot change\n",
    "    \"monotonicity\": {\"age\": Monotonicity.INCREASING}, # domain constrain on whether\n",
    "    \"causal_inc\": [], # causal increase, pairs of features where if one increases, the other one must increase as well, e.g. [(\"education\", \"age\")]\n",
    "    \"greater_than\": [], # inter-feature dependence, one feature must always be > anohter feature, a list of pairs, e.g. [(\"# total missed payments\",  \"# missed payments last year\")]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "dhandler = DataHandler(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    **config,\n",
    "    # optionally, one can provide the list of feature names (and target name) but here we pass pandas dataframe (and a series) with named columns, which will be taken as feature names\n",
    ")\n",
    "\n",
    "X_train_enc = dhandler.encode(X_train, normalize=True, one_hot=True)\n",
    "y_train_enc = dhandler.encode_y(y_train, one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd290112-1fb4-4cfa-b041-fb806b7ccd58",
   "metadata": {},
   "source": [
    "### Train a Neural Network\n",
    "\n",
    "here we utilize our wrapper, but any ReLU NN that can be exported to ONNX should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06e906-906e-4882-8f15-d85eac749590",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NNModel(dhandler.encoding_width(True), [20, 10], 1)\n",
    "nn.train(X_train_enc, y_train_enc)\n",
    "# output it to ONNX file\n",
    "nn.save_onnx(\"tmp_nn.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd6685-9af5-4af5-acb5-9ab37f01e067",
   "metadata": {},
   "source": [
    "### Train an SPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd8090-daf0-43e6-93f6-e2c06e7190a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this can take long... \n",
    "# setting \"min_instances_slice\":1000 argument leads to faster training by allowing leaves to be formed on >=1000 samples (default is 200)\n",
    "\n",
    "# data should be numpy array of original (non-encoded) values, should include the target as last feature\n",
    "spn_data = np.concatenate([X_train.values, y_train.values], axis=1) \n",
    "spn = SPN(spn_data, dhandler, normalize_data=False, learn_mspn_kwargs={\"min_instances_slice\":1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6bc46-81e7-4ce7-b153-699cae5e086d",
   "metadata": {},
   "source": [
    "## Find Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4934e621-421d-4999-a232-d3b4ac9f1917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 24054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n = 1 # top-n counterfactuals to look for (obtaining more than 1 is implemented only for Gurobi solver)\n",
    "time_limit = 120 # number of seconds to look for a counterfactual\n",
    "# solver to choose\n",
    "solver_name = \"gurobi\" # Gurobi solver was used in the original experiments. \n",
    "# solver_name = \"appsi_highs\" # This is an open-source solver. Install with: $ pip install highspy\n",
    "\n",
    "lice = LiCE(\n",
    "    spn,\n",
    "    nn_path=\"tmp_nn.onnx\",\n",
    "    data_handler=dhandler,\n",
    ")\n",
    "\n",
    "# take a sample\n",
    "# np.random.seed(42)\n",
    "np.random.seed(1)\n",
    "i = np.random.randint(X_test.shape[0])\n",
    "print(i, X_test.shape[0])\n",
    "\n",
    "sample = X_test.iloc[i]\n",
    "enc_sample = dhandler.encode(X_test.iloc[[i]]) # to keep 2 dimensions\n",
    "# enc_sample = dhandler.encode(X_test.iloc[i]) # to keep 2 dimensions\n",
    "prediction = nn.predict(enc_sample) > 0 # we assume binary classification without sigmoid activation in the end\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815ec14-e089-42b4-99d9-ce909bfb9c4d",
   "metadata": {},
   "source": [
    "### Thresholding variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f93e691-caa6-4c1d-8b20-b2763e4b7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.994575, 63.0, 1.0, 0.004011, 3995.62069, 4.0, 2.0, 0.0, 1.0, 0.0],\n",
      "      dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time_total': 11.4788535819971,\n",
       " 'time_solving': 9.91448436799692,\n",
       " 'time_building': 1.5409484319970943,\n",
       " 'optimal': True,\n",
       " 'll_computed': [-21.250178059015703],\n",
       " 'dist_computed': [2.6760164239499087]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lls = spn.compute_ll(spn_data)\n",
    "quartile_ll = np.quantile(lls, 0.25) # threhsold on CE likelihood\n",
    "\n",
    "thresholded = lice.generate_counterfactual(\n",
    "    sample,\n",
    "    not prediction,\n",
    "    ll_threshold=quartile_ll,\n",
    "    n_counterfactuals=top_n, \n",
    "    time_limit=time_limit, \n",
    "    solver_name=solver_name\n",
    ")\n",
    "print(thresholded)\n",
    "lice.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e320f2-84c6-406a-abb0-99e0f9b3ec36",
   "metadata": {},
   "source": [
    "### Optimizing variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26134785-a72f-48fe-86b1-1dab3a56449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.762035, 63.0, 1.0, 0.004011, 3528.198147, 4.0, 2.0, 0.0, 1.0,\n",
      "       0.0], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time_total': 7.681302868004423,\n",
       " 'time_solving': 6.24439866701141,\n",
       " 'time_building': 1.4052089839969995,\n",
       " 'optimal': True,\n",
       " 'll_computed': [-25.047672688979794],\n",
       " 'dist_computed': [1.1741684347788122]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.1 # coefficient of the linear combination in the objective\n",
    "# taking a value approximately equal to (mean CE distance)/(mean mean CE log-likelihood) works well.\n",
    "# running the thresholding variant first and then estimating some alpha is a reasonable approach\n",
    "\n",
    "optimized = lice.generate_counterfactual(\n",
    "    sample,\n",
    "    not prediction,\n",
    "    ll_opt_coefficient=alpha,\n",
    "    n_counterfactuals=top_n, \n",
    "    time_limit=time_limit, \n",
    "    solver_name=solver_name\n",
    ")\n",
    "print(optimized)\n",
    "lice.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe8614-81ea-45bc-8f81-babc6f0c82dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
